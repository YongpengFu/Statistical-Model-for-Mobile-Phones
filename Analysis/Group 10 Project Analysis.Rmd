---
title: "Mobile Phones Selling Price Report"
author:
- Yongpeng Fu (10182778), Rudy Brown (10057171), Jose Palacios (30190988),
- Stuart Finley(30191070), Andrii Voitkiv(30199373)
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  pdf_document:
    extra_dependencies:
    - bbm
    - xcolor
    toc: yes
  lof: yes
  lot: yes
  html_document:
    toc: yes
    df_print: paged
geometry: margin=3cm
subtitle: Proposal for final project (MDSA Winter 2023)
urlcolor: blue
header-includes: \usepackage{fvextra} \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
  \usepackage[nottoc]{tocbibind}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(survey) #Used for statistical analysis
library(sampling) #Used for sample data
library(ggplot2) #Used for plot
library(tibble) #used for nice display dataframe
library(magrittr) #Used for %>% 
library(tidyverse) #Used to manipualte dataframe
library(dplyr) # Used for easy manipualte rows and columns
library(plyr) #Used for mapping vector values
library(stringr) #Used to manipulate string
library(gridExtra) #Used to arrange the ggplot chart
```


\pagebreak

# Introduction

Mobile phones are everywhere, so are the prices. Despite still having the word "phone" in the name, a typical modern smartphone has much more features than just to make and receive calls. They are boasting a staggering range of applications like brand, memory, storage, camera, resolution, just to name a few. All these cutting edge technology and features packed in one little device does not come without a cost. A [2020 review](https://www.thisismoney.co.uk/money/bills/article-8548235/High-end-mobile-phones-price-soared-490-20-years.html) of premium mobile phones shows a staggering _490%_ rise in the last two decades.

With so many mobile phones on the market, it can be difficult to decide which one you want to buy. As a customer, we are particularly interested in finding some relation between all these features and its selling price. To this purpose, we collected the [MobilePhone's dataset](https://www.kaggle.com/datasets/sudhanshuy17/mobilephone) from Kaggle and apply a set of statistical analysis hoping to answer some guiding questions:

1. Can we estimate the average price for mobile phones?
2. What is the impact of each mobile phone's feature on the selling price?
3. Can a classification model to distinguish the selling price range?
3. Can we build a decent model to predict the selling price for a mobile phone?


# Dataset and Cleanup

The initial dataset consists of 8 columns and 28,036 rows and no missing values. These 8 columns are:

* **Model**: categorical variables with sub-classes. These names include the color of the unit
and its storage capacity. The latter being also listed as a separate column. - **Independent Variable**
* **Company**: categorical variable. Name of the phone's manufacturer. - **Independent Variable**
* **Price**: continuous variable. Units in Indian Rupees. - **Dependent Variable**
* **Rating**: continuous variable. Units in Indian Rupees. - **Independent Variable**
* **Number of ratings**: discrete variable: a simple count. - **Independent Variable**
* **Total reviews**: discrete variable: a simple count. - **Independent Variable**
* **RAM size**: categorical variable. RAM specification of the phone. - **Independent Variable**
* **ROM size**: categorical variable. Storage (non-volatile memory) capacity of the phone. - **Independent Variable**

Some initial steps can be completed to clean the dataset and create new variables which can be used in our analysis. The initial steps for cleaning the dataset are as follows:

1. Remove any duplicates in the dataset;
2. Because **Model** column contains sub-class of a mobile phone, we decide to further break it down to _Model_ and _Color_;
3. Convert all units from **RAM size** and **ROM size** measure to GB and then remove unit suffix;
4. Add additional column to segment the **Price** into 4 different levels;
5. Add additional column to determine if a phone has %G feature or not based on **Model** information.

```{r Cleanup}
mobile_dataset <- read.csv("./Updated_Mobile_Dataset.csv")
#Step 0: convert Model and Company letter to uppercase.
mobile_dataset$Model <- toupper(mobile_dataset$Model)
mobile_dataset$Company <- toupper(mobile_dataset$Company)
#Break down Model column into Model only and Color columns
#Step 1: remove the Company name from Model
Model_no_Company <- stringr::str_remove(mobile_dataset$Model,mobile_dataset$Company) %>% trimws(., which = c("both"))
#Step 2: remove anything after parentheses to get Model only info
mobile_dataset$Model_Only <- stringr::str_replace(Model_no_Company, " \\s*\\([^\\)]+\\)", "")
#Step 3: Get the color information from inside the last ()
#Step 3.1: Get the parenthesis and what is inside from the last ()
Model_no_Company_parenthesis <- stringr::str_extract(Model_no_Company, "(?<=\\()([^()]*?)(?=\\)[^()]*$)")
#step 3.2: Get the color by just retaining the info before ,
mobile_dataset$Color <- gsub(",.*$", "", Model_no_Company_parenthesis)
#Step 4: Remove duplicated rows in the dataset
mobile_dataset <- mobile_dataset[!duplicated(mobile_dataset),]
#Step 5: cut the price based on the percentile into 4 different levels
mobile_dataset <- mobile_dataset %>% mutate(Price_Level = ntile(Price, n = 4))
#Step 5.1: map each number level to the character
from <- c(1,2,3,4)
to <- c("Low", "Medium", "High", "Very High")
mobile_dataset$Price_Level <- mapvalues(mobile_dataset$Price_Level, from = from, to = to)


#Step 6: Get the numeric part of RomSize (remove GB and MB, but convert MB to GB), discard any record that no numeric in RomSize
#Step 6.1: there are some data input errors for RamSize and RomSize. In the records where RomSize is "Not Known" are swapped with RamSize, so we need to correct that.
RamSize_temp <- ifelse(mobile_dataset$RomSize == "Not Known", "0 GB", mobile_dataset$RamSize)
mobile_dataset$RomSize <- ifelse(mobile_dataset$RomSize == "Not Known", mobile_dataset$RamSize, mobile_dataset$RomSize)
mobile_dataset$RamSize <- RamSize_temp
#Step 6.2: split RomSize into two columns with size number and unit, and convert MB to 1/1000GB, KB to 1/1000000GB
mobile_dataset$RamSize_Ori <- mobile_dataset$RamSize
mobile_dataset$RomSize_Ori <- mobile_dataset$RomSize
mobile_dataset <- mobile_dataset %>% separate(RomSize, c("RomSize_num", "RomSize_Unit")) %>% mutate(RomSize_Unit= mapvalues(.$RomSize_Unit, from = c("GB", "MB", "KB"), to = c(1, 1/1000, 1/1000000)))
#step 6.3: remove any rows that are not numeric value for RomSize
mobile_dataset <- mobile_dataset[!is.na(as.numeric(mobile_dataset$RomSize_num)),]
mobile_dataset$RomSize_num <- as.numeric(mobile_dataset$RomSize_num)
mobile_dataset$RomSize_Unit <- ifelse(is.na(as.numeric(mobile_dataset$RomSize_Unit)), 0, as.numeric(mobile_dataset$RomSize_Unit))
#Step 6.4: generate the final column RomSize_inGB
mobile_dataset$RomSize_inGB <- mobile_dataset$RomSize_num * mobile_dataset$RomSize_Unit


#Step 7: Get the numeric part of RamSize (remove GB and MB, but convert MB to GB), discard any record that no numeric in RamSize
#Step 7.1: split RamSize into two columns with size number and unit, and convert MB to 1/1000GB
mobile_dataset <- mobile_dataset %>% separate(RamSize, c("RamSize_num", "RamSize_Unit")) %>% mutate(RamSize_Unit= mapvalues(.$RamSize_Unit, from = c("GB", "MB"), to = c(1, 1/1000)))
#step 7.2: remove any rows that are not numeric value for RamSize
mobile_dataset <- mobile_dataset[!is.na(as.numeric(mobile_dataset$RamSize_num)),]
mobile_dataset$RamSize_num<- as.numeric(mobile_dataset$RamSize_num)
mobile_dataset$RamSize_Unit <- as.numeric(mobile_dataset$RamSize_Unit)
#Step 7.3: generate the final column RamSize_inGB
mobile_dataset$RamSize_inGB <- mobile_dataset$RamSize_num * mobile_dataset$RamSize_Unit


#Step 8: Create a new column to determine if the phone is 5G or not
mobile_dataset$Is_5G <- ifelse(str_detect(mobile_dataset$Model_Only, "5G"), "Yes", "No")
#Step 9: only keep the columns we need
column_names <- c("Model", "Company", "Price", "Rating", "No_of_ratings", "TotalReviwes", "Model_Only", "Color", "Price_Level", "RamSize_inGB", "RomSize_inGB", "RamSize_Ori", "RomSize_Ori", "Is_5G" )
mobile_dataset <- mobile_dataset[column_names]

# #Step 9: final check up. Convert all company name to uppercase and then do a final duplicated removal
# mobile_dataset$Company <- toupper(mobile_dataset$Company)
# mobile_dataset <- mobile_dataset[!duplicated(mobile_dataset),]
write.csv(mobile_dataset, file = './Cleaned_Mobile_Dataset.csv', row.names = F)
```



After cleaning and breaking down columns, the dataset now consists of 14 columns and 725 rows and no missing values. These 14 columns are:

* **Model**: categorical variables with sub-classes. These names include the color of the unit
and its storage capacity. The latter being also listed as a separate column. - **Independent Variable**
* **Company**: categorical variable. Name of the phone's manufacturer. - **Independent Variable**
* **Price**: continuous variable. Units in Indian Rupees. - **Dependent Variable**
* **Rating**: continuous variable. Units in Indian Rupees. - **Independent Variable**
* **Number of ratings**: discrete variable: a simple count. - **Independent Variable**
* **Total reviews**: discrete variable: a simple count. - **Independent Variable**
* **Model_Only**: categorical variable: only contains the model information of a mobile phone. - **Independent Variable**
* **Color**: categorical variable: color of a mobile phone. - **Independent Variable**
* **Price_Level**: The price level of a mobile phone, with levels of "Low", "Medium", "High", "Very High". - **Independent Variable**
* **RamSize_inGB**: continuous variable. RAM specification of the phone in GB. - **Independent Variable**
* **RomSize_inGB**: continuous variable. Storage (non-volatile memory) capacity of the phone in GB. - **Independent Variable**
* **RamSize_Ori**: categorical variable. RAM specification of the phone, original information. - **Independent Variable**
* **RomSize_Ori**: categorical variable. Storage (non-volatile memory) capacity of the phone, original information. - **Independent Variable**
* **Is_5G**: categorical variable. If the phone has 5G service or not. - **Independent Variable**


```{r Load Data}
mobile_dataset <- as_tibble(read.csv("/Users/berg/DataspellProjects/Statistical-Model-for-Mobile-Phones/Analysis/Cleaned_Mobile_Dataset.csv"))
#Specify the level for Price_Level column
mobile_dataset$Price_Level <- factor(mobile_dataset$Price_Level, levels = c("Low", "Medium", "High", "Very High"))
mobile_dataset %>% head(4)
```
**Table 1**: The cleaned-up dataset for Mobile Phone

The dataset and detailed analysis can be found at this [repository](https://github.com/YongpengFu/Statistical-Model-for-Mobile-Phones). 

# Scope of Analysis

Our team is finalizing what the full analysis of the dataset will look like, but a preliminary template and breakdown of work by team member has been included below. The different colors represent which components of the project different team members would take on. It is anticipated that all members will assist in the finalization of the report.

![Project Workflow](./Img/project-workflow.png)
\pagebreak

#  Chapter 4: Exploratory Data Analysis
## 4.1: A summary of the dataset
The dimension of the cleaned dataset is 726 rows and 14 columns. A summary of the data is as follows:
```{r 4.1 Summary, results='hold'}
mobile_dataset <- as_tibble(read.csv("./Cleaned_Mobile_Dataset.csv"))
#Specify the level for Price_Level column
mobile_dataset$Price_Level <- factor(mobile_dataset$Price_Level, levels = c("Low", "Medium", "High", "Very High"))
mobile_dataset %>% summary()
```
**Table 2**: A summary for Mobile Phone dataset

## 4.2: Exploratory Data Analysis
This section is focused on the exploration of relation between variables using various visualization techniques.

The main target is Price in the dataset. In the following visualization it shows the distribution of Mobile Phone price with long tail towards to the high end. The average price is 15902 Rupees. Most price falls in the range of 50000 Rupees. One really stands out price range (arrow indicated) is 1000-2000 Rupees with the highest frequency.

```{r 4.2.1, fig.height=4, fig.width=10, results='hold'}
ggplot(data = mobile_dataset, mapping = aes(x=Price)) +
        geom_histogram(color="black", fill="white", bins = 100)+
        labs(y="Count", x="Price in Rupees", subtitle="Distribution of Mobile Phone price") +
        geom_vline(aes(xintercept = 9500), color="blue", linetype="dashed", size=0.4) +
        geom_vline(aes(xintercept = 24400), color="blue", linetype="dashed", size=0.4) +
          geom_vline(aes(xintercept = 55000), color="blue", linetype="dashed", size=0.4) +
# Add annotation to the plot
        annotate("text", x = 0, y = 200, label = "Cheap", size = 5, color = "blue") +
        annotate("text", x = 15000, y = 200, label = "Affordable", size = 5, color = "blue") +
        annotate("text", x = 30000, y = 200, label = "Expensive", size = 5, color = "blue") +
        annotate("text", x = 55000, y = 200, label = "Luxury", size = 5, color = "blue")
```
The following figure is to break down the Price by different phone-making companies. There are a total of 37 companies in the dataset. Iin consistent with previous figure about Price distribution, we see a big portion of Price falls between 9000 (left dash line) and 40000 (right dash line) Rupees. _Apple_ alone contributes the most of high priced Mobile Phones, while companies like from _NOKIA_ to _GFIVE_ contribute to the low-priced ones.
```{r 4.2.2,fig.height=5, fig.width=10, results='hold'}
ggplot(data = mobile_dataset, mapping = aes(y = reorder(Company, Price), x = Price)) +geom_boxplot()+ geom_line() +
    sapply(c(9000, 40000), function(xint) geom_vline(aes(xintercept = xint), color="blue", linetype="dashed", size=0.4)) + labs(y="Company", x="Price in Rupees", 
       subtitle="Boxplot for Mobile Phone price from different companies")
```
The Price is further broken down by their 5G services. Interestingly, neither high-priced nor low-priced Mobile Phones have equipped 5G service. In contrast, almost all middle-priced Mobile Phones have 5G service. Price for those with 5G service are slightly more expensive than those without. NOTE: the dashed line indicates the price between 9000 (left dash line) and 40000 (right dash line) Rupees.

```{r 4.2.3, fig.height=5, fig.width=10, results='hold'}
ggplot(data = mobile_dataset, mapping = aes(y = reorder(Company, Price), x = Price, color = Is_5G)) +geom_boxplot(position=position_dodge(width = 0.8))+ geom_line() +
    sapply(c(9000, 40000), function(xint) geom_vline(aes(xintercept = xint), color="blue", linetype="dashed", size=0.4)) + labs(y="Company", x="Price in Rupees", 
       subtitle="Boxplot for Mobile Phone price from different companies with 5G service (No / Yes)") + facet_wrap(~Is_5G)
```
The pattern is more obvious when we provide color for 4 different price level ("Low", "Medium", "High", "Very High"). Although mobile phones from companies like APPLE, GOOGLE, ASUS and NOTHING have no 5G service, their price are all very high. It is worth investigating if some other attributes like brand effect, Storage capacity (Rom Size), and calculation power (Ram Size) are playing roles. Most Mobile Phones (except MI) with 5G service, again, have a higher proportion falling in a Very High price level, compared to the counterparts without 5G service. Almost all the rest mobile phones without 5G service fall in a Low price level.

```{r 4.2.4, fig.height=5, fig.width=10, results='hold'}
ggplot(data = mobile_dataset,mapping = aes(y =reorder(Company, Price), fill = Price_Level)) + geom_bar(stat = "count", position="fill") + labs(y="Company", x="Percentage", 
       subtitle="Percent Boxplot for Mobile Phone price from different companies with 5G service (No / Yes)") + facet_wrap(~Is_5G)
```

Next, we explored some quantitative features with respect to the Mobile Phone price. The first scatter plot shows an obvious positive relation between Rating and Price as the smooth line indicates. The higher the Rating, the higher the Price. And this holds when we remove those bottom left 2 outlier data points. 
```{r 4.2.5, fig.height=4, fig.width=10, results='hold'}
#The first plot is one with outlier
plot1 = ggplot(data = mobile_dataset,mapping = aes(x = Rating, y = Price)) + geom_point(alpha=0.3) + geom_smooth(se=T) + 
  geom_segment(aes(x = 2.6, y = 20000, xend = 2.67, yend = 10000),lineend = "round",linejoin = "round",arrow = arrow(length = unit(0.5, "cm"))) +   
  geom_point(data=mobile_dataset[mobile_dataset$Rating<3.0,], aes(x = Rating, y = Price), color='red') +
  labs(y="Price in Rupees", x="Rating", subtitle="Relation between rating and price")

#The first plot is a one with outliers removed
plot2 = ggplot(data = mobile_dataset[mobile_dataset$Rating>3.0, ],mapping = aes(x = Rating, y = Price)) + geom_point(alpha=0.3) + geom_smooth(se=T) +
  labs(y="Price in Rupees", x="Rating", subtitle="Relation between rating and price after removing \nbottom left 2 outliers")

grid.arrange(plot1, plot2, ncol=2)
```

The second scatter plot shows the relation between Total number of rating and Price. As the smooth line indicates, there is no obvious correlation between them. The result holds even when we remove some seemingly outliers on the far right end.
```{r 4.2.6, fig.height=4, fig.width=10, results='hold'}
ggplot(data = mobile_dataset,mapping = aes(x = No_of_ratings, y = Price)) + geom_point(alpha=0.3) + geom_smooth()+ labs(y="Price in Rupees", x="Total number of rating", subtitle="Relation between total nubmer of rating and price")
```
The same pattern is also observed in the third scatter plot where relation between Total number of reviews and Price is plotted. As the smooth line indicates, there is no obvious correlation between them. The result holds even when we remove some seemingly outliers on the far right end.
```{r 4.2.7, fig.height=4, fig.width=10, results='hold'}
ggplot(data = mobile_dataset,mapping = aes(x = TotalReviwes, y = Price)) + geom_point(alpha=0.3) + geom_smooth()+ labs(y="Price in Rupees", x="Total number of reviews", subtitle="Relation between total nubmer of reviews and price")
```
In the fourth scatter plot, below, there seems a slight positive relation between Ram size (in GB) and the Price. Ram is normally associated with speed and performance of an operating system. The higher ram is, the better it is in speed and performance. It makes sense that a mobile phone with a larger Ram will charge more. However, because nowadays most mobile phones are very fast and stable, people wont tell too much difference, making the added on value from ram is only weekly associated with price.
```{r 4.2.8, fig.height=4, fig.width=10, results='hold'}
ggplot(data = mobile_dataset,mapping = aes(x = RamSize_inGB, y = Price)) + geom_point(alpha=0.3) + geom_smooth(se=T)+ labs(y="Price in Rupees", x="Ram Size in GB", subtitle="Relation between Ram size (in GB) and price")
```
In the final scatter plot, again, we have two charts, one the original dataset, the other with outlier removed. Both cases tells the same story. In contrast to the previous scatter plot (Ram size (in GB) and the Price), there is a very obvious positive linear relation between Rom size (in GB) and the Price. This makes sense because often times a mobile phone is more limited by its non-volatile memory space than its speed & performance.
```{r 4.2.9, fig.height=4, fig.width=10, results='hold'}
#The first plot is a one with outliers
plot1 = ggplot(data = mobile_dataset,mapping = aes(x = RomSize_inGB, y = Price)) + geom_point(alpha=0.3) + geom_smooth(se=T, method = lm)+ 
  geom_segment(aes(x = 490, y = 100000, xend = 500, yend = 90000),lineend = "round",linejoin = "round",arrow = arrow(length = unit(0.5, "cm"))) +   
  geom_point(data=mobile_dataset[mobile_dataset$RomSize_inGB>400,], aes(x = RomSize_inGB, y = Price), color='red') +
  labs(y="Price in Rupees", x="Rom Size in GB", subtitle="Relation between Rom size (in GB) and price")

#The second plot is a one with outliers removed
plot2 = ggplot(data = mobile_dataset[mobile_dataset$RomSize_inGB<400, ],mapping = aes(x = RomSize_inGB, y = Price)) + geom_point(alpha=0.3) + geom_smooth(se=T,method = lm) +
  labs(y="Price in Rupees", x="Rom Size in GB", subtitle="Relation between Rom size (in GB) and price")

grid.arrange(plot1, plot2, ncol=2)
```

\pagebreak

## New price level variable
```{r}
# Break Price into 4 groups:
classify_price_level <- function(price) {
  if (price <= 9500) {
    return("Cheap")
  } else if (price > 9500 & price <= 24400) {
    return("Affordable")
  } else if (price > 24400 & price <= 55000) {
    return("Expensive")
  } else {
    return("Luxury")
  }
}

mobile_dataset$Price_level_av <- sapply(mobile_dataset$Price, classify_price_level)

# Convert Price_level_av to factor
mobile_dataset$Price_level_av <- factor(mobile_dataset$Price_level_av, levels = c("Cheap", "Affordable", "Expensive", "Luxury"))

# What proportion of mobile phones are in each price level?
prop.table(table(mobile_dataset$Price_level_av))
```

```{r}
# Bar plot of proportion of mobile phones in each price level
ggplot(data = mobile_dataset, mapping = aes(x = Price_level_av)) + geom_bar() + labs(y="Proportion", x="Price level", subtitle="Proportion of mobile phones in each price level")
```

## Sampling estimation
### Simple random sampling (SRS)
```{r}
# Calculate the population mean and its standard deviation
pop_mean = mean(mobile_dataset$Price)
pop_sd = sd(mobile_dataset$Price)
# Print the results
print(paste("The population mean is", pop_mean))
print(paste("The population standard deviation is", pop_sd))
```
```{r}
set.seed(2023)
n <- 100
# Simple random sampling
ix <- sample(1:nrow(mobile_dataset), n, replace = FALSE)
srs <- mobile_dataset[ix,]
# Calculate the sample mean and its standard deviation
srs_mean = mean(srs$Price)
srs_sd = sd(srs$Price)
# Print the results
print(paste("The sample mean is", srs_mean))
print(paste("The sample standard deviation is", srs_sd))

```

```{r}
# Method 1: Estimate the population mean and its standard deviation using survey package
library("survey")
# Simple random sample of 5000 observations
set.seed(2023)
N = nrow(mobile_dataset)
n = 100
ix <- sample(1:N, n, replace = FALSE)
srs <- mobile_dataset[ix,]
# Add a sampling weight column and finite population correction factor to the sample
srs = data.frame(srs, pw = rep(N/n, n), fpc = rep(N, n))
svy1 = svydesign(id = ~0, strata = NULL, data = srs, weights = ~pw, fpc = ~fpc)
# Estimate the population mean and its standard deviation
srs_mean = svymean(~Price, design = svy1)
# Print the results
srs_mean

```

```{r}
# Calculate confidence interval for the population mean of usd_pledged_real
confint(srs_mean ,level = 0.95, df=degf(svy1))
```

```{r fig.height=10, fig.width=6}
# Method 2: Estimate the population mean and its standard deviation using simulation
library(ggplot2)

mean_SD_facet <- function(s, n, N){ # s denotes how many times you draw the sample, n denotes the sample size
  set.seed(2023)
  sam_mean <- rep(0, s)
  sam_sd <- rep(0, s)
  for (i in 1:s){
    ind <- sample(seq(0, N), n, replace=FALSE)
    sam_mean[i] <- mean(mobile_dataset$Price[ind])
    sam_sd[i] <- sd(mobile_dataset$Price[ind])
  }
  es_mean <- mean(sam_mean)
  es_var <- sam_sd[1]^2/n*(1-n/N)
  es_var2 <- sd(sam_mean)^2
  print(c(es_mean,es_var,es_var2))
  # Plot the histogram of the sample mean using ggplot2
  ggplot(data.frame(sam_mean), aes(x=sam_mean)) +
          geom_histogram(binwidth=500) +
          geom_vline(xintercept=mean(mobile_dataset$Price), color="red", size=1) +
          geom_text(x=mean(mobile_dataset$Price), y=0, label="Population mean", vjust=-1) +
          labs(title=paste("Sample size =", n, "\n", "Draw sample times =", s), x="Sample mean", y="Frequency")
}

# Create a list of parameters for the function
params_list <- list(list(s = 50, n = 50), list(s = 50, n = 100), list(s = 50, n = 200),
                    list(s = 50, n = 100), list(s = 100, n = 100), list(s = 200, n = 100))

# Create a list of plots
plots_list <- lapply(params_list, function(params) mean_SD_facet(params[["s"]], params[["n"]], N))

# Plot the subplots
library(gridExtra)
grid.arrange(grobs = plots_list, ncol = 3, nrow = 2)

```

### Stratified random sampling
```{r}
# Calculate proportion of each category and make a data frame
prop = table(mobile_dataset$Price_level_av)/nrow(mobile_dataset)
# Sort the data in data frame order
prop = prop[unique(mobile_dataset$Price_level_av)]
# Create a vector of the proportion of each category
prop = as.vector(prop)
# Calculate the sample size for each strata
strata_size = round(prop * 201)
# Add 1 ro Luxury strata to make the total sample size 201
strata_size[4] = strata_size[4] + 1
# Test if the sum of the sample size equals 100
print(paste("The sample size is:", sum(strata_size)))
# Print the strata sizes
print(strata_size)
```
```{r}
table(mobile_dataset$Price_level_av)
```
```{r}
library("sampling")
set.seed(2023)
# Sampling strata_size observations from each stratum with simple random sampling
idx = sampling::strata(mobile_dataset, stratanames = "Price_level_av", size = strata_size, method = "srswor")
# Create a new data frame with the sampled observations
strata_srs = getdata(mobile_dataset, idx)
# Add columns for sampling weight and finite population correction factor
strata_srs = data.frame(strata_srs, pw = rep(N/nrow(strata_srs), nrow(strata_srs)), fpc = c(rep(470, 130), rep(106, 29), rep(146, 40), rep(3, 2)))
# Estimate the population mean and its standard deviation
svy2 = svydesign(id = ~1, strata = ~Price_level_av, data = strata_srs, weights = ~pw, fpc = ~fpc)
me2 = svymean(~Price, svy2)
# Print the results
print(me2)
```

```{r}
# Calculate confidence interval for the population mean of usd_pledged_real
confint(me2, level = 0.95, df=degf(svy2))
```

### Cluster sampling
```{r}
# Calculate the number of unique clusters in the data
n_clusters = length(unique(mobile_dataset$Company))
# Print unique values of the country column
print(unique(mobile_dataset$Company))
# Print the length of the unique values
print(paste("Number of clusters (companies) in the dataset:", n_clusters))
```

```{r}
library("sampling")
library("survey")
# Select two clusters with simple random sampling method using the sampling package
set.seed(2023)
n_choose = 5
idx = sampling::cluster(mobile_dataset, clustername = "Company", size = n_choose, method = "srswor")
# Create a new data frame with the sampled observations
cluster_srs = getdata(mobile_dataset, idx)
# Print the clusters (countries) in the sample
print(paste(
        "The clusters (countries) in the sample are:",
        paste(unique(cluster_srs$Company), collapse = ", ")
))
```

```{r}
# Calculate the sampling weight and finite population correction factor
cluster_srs = data.frame(cluster_srs, pw = rep(n_clusters/n_choose, nrow(cluster_srs)), fpc = rep(n_clusters, nrow(cluster_srs)))
# Estimate the population mean and its standard deviation
svy3 = svydesign(id = ~Company, data = cluster_srs, weights = ~pw, fpc = ~fpc)
me3 = svymean(~Price, svy3)
# Print the results
print(me3)
```

```{r}
# Calculate confidence interval for the population mean of usd_pledged_real
confint(me3, level = 0.95, df=degf(svy3))
```

## Multiple Linear Regression
```{r}
# Create a new data frame with the variables of interest
column_names_mlr <- c("Price", "Rating", "No_of_ratings", "TotalReviwes", "RamSize_inGB", "RomSize_inGB", "Is_5G" ) # "Company"
mobile_dataset_mlr <- mobile_dataset[column_names_mlr]
```

```{r}
# Calculate proportion of each category and make a data frame
prop = table(mobile_dataset$Price_level_av)/nrow(mobile_dataset)
# Sort the data in data frame order
prop = prop[unique(mobile_dataset$Price_level_av)]
# Create a vector of the proportion of each category
prop = as.vector(prop)
# Calculate the sample size for each strata
strata_size = round(prop * 544)
# Test if the sum of the sample size equals 100
print(paste("The sample size is:", sum(strata_size)))
# Print the strata sizes
print(strata_size)
library("sampling")
set.seed(2023)
# Sampling strata_size observations from each stratum with simple random sampling
idx = sampling::strata(mobile_dataset, stratanames = "Price_level_av", size = strata_size, method = "srswor")
# Create a new data frame with the sampled observations
train_data <- data.frame(getdata(mobile_dataset, idx))
# Get index values of train data
train_index <- as.numeric(rownames(train_data))
# Get test data by excluding index values of train data
test_data <- mobile_dataset[-train_index, ]
# Select colunms for multiple linear regression
column_names_mlr <- c("Price", "Rating", "No_of_ratings", "TotalReviwes", "RamSize_inGB", "RomSize_inGB", "Is_5G" ) # "Company"
train_data <- train_data[column_names_mlr]
test_data <- test_data[column_names_mlr]
```



```{r}

# Split the data into training and test sets
# set.seed(2023)
# train_index <- sample(1:nrow(mobile_dataset_mlr), 0.8 * nrow(mobile_dataset_mlr))
# train_data <- mobile_dataset_mlr[train_index, ]
# test_data <- mobile_dataset_mlr[-train_index, ]
```

```{r message = FALSE, warning = FALSE}
# Explore collinearity between the variables
# Plot the correlation matrix with the help of the ggally package
library('GGally')
library('ggplot2')
ggpairs(train_data, lower = list(continuous = "smooth_loess", combo = "facethist", discrete = "facetbar", na = "na")) +
        scale_color_gradient(high = "red", low = "blue")
```


```{r}
# Build a multiple linear regression model
mlr_full_model <- lm(Price ~ Rating + No_of_ratings + TotalReviwes + RamSize_inGB + RomSize_inGB + factor(Is_5G), data = train_data)
```

```{r message = FALSE, warning = FALSE}
# Check the “variance inflation factor” for each coefficient using imcdiag function from the package "regclass"
library('regclass')
VIF(mlr_full_model)
```
From the VIF values, we can see that two variables are collinear. And form the correlation matrix the relationship between the variables is also high. So, we will remove the variable with the highest VIF value, that is "No_of_ratings".

```{r}
# Update the model by removing the variable with the highest VIF value
mlr_updated_model <- lm(Price ~ Rating + TotalReviwes + RamSize_inGB + RomSize_inGB + factor(Is_5G), data = train_data)
summary(mlr_updated_model)
```
From the individual t-test, we can see that the variable "Is_5G" is not significant. So, we will remove it from the model.

```{r}
# Update the model by removing the variable with the insignificant p-value
mlr_updated_model <- lm(Price ~ Rating + TotalReviwes + RamSize_inGB + RomSize_inGB, data = train_data)
summary(mlr_updated_model)
```
Now, all the variables are significant. So, we will use this model for prediction.
The adjusted R-squared value is `r summary(mlr_updated_model)$adj.r.squared`, which means that the model explains `r summary(mlr_updated_model)$adj.r.squared * 100`% of the variance in the data. Let's see how well the model performs on the test data.

```{r}
# Predict the price of the test data
test_data$predicted_price_mlr_base <- predict(mlr_updated_model, test_data)
# Calculate the mean square error
mse <- mean((test_data$Price - test_data$predicted_price_mlr_base)^2)
# Print the mean square erro
print(paste("Mean square error:", mse))
```

```{r}
# Check assumptions of the model
# Plot the residuals vs fitted values
plot(mlr_updated_model, which = 3)
```

```{r}
library(lmtest)
bptest(mlr_updated_model)
```
The output displays the Breusch-Pagan test that results from the MLR base model. The p-value = 0 < 0.05, indicating that we reject the null hypothesis. Therefore, the test provides evidence to suggest that heteroscedasticity is present - non-constant variance.


Let's improve the model by trying interaction terms.
```{r}
# Build a multiple linear regression model with interaction terms
mlr_interaction_model <- lm(Price ~ Rating + TotalReviwes + RamSize_inGB + RomSize_inGB + Rating:TotalReviwes + Rating:RamSize_inGB + Rating:RomSize_inGB + TotalReviwes:RamSize_inGB + TotalReviwes:RomSize_inGB + RamSize_inGB:RomSize_inGB, data = train_data)
summary(mlr_interaction_model)
```

```{r}
# Update the model by removing the variable with the insignificant p-value
mlr_interaction_updated_model <- lm(Price ~ Rating + TotalReviwes + RamSize_inGB + RomSize_inGB + Rating:RamSize_inGB + Rating:RomSize_inGB + TotalReviwes:RomSize_inGB + RamSize_inGB:RomSize_inGB, data = train_data)
summary(mlr_interaction_updated_model)
```

The adjusted R-squared value is `r summary(mlr_interaction_updated_model)$adj.r.squared`, which means that the model explains `r summary(mlr_interaction_updated_model)$adj.r.squared * 100`% of the variance in the data. Let's see how well the model performs on the test data.

```{r}
# Predict the price of the test data
test_data$predicted_price_mlr_interaction <- predict(mlr_interaction_updated_model, test_data)
# Calculate the mean square error
mse <- mean((test_data$Price - test_data$predicted_price_mlr_interaction)^2)
# Print the mean square error
print(paste("Mean square error:", mse))
```

```{r}
# Check assumptions of the model
# Plot the residuals vs fitted values
plot(mlr_interaction_updated_model, which = 3)
```

```{r}
library(lmtest)
bptest(mlr_interaction_updated_model)
```

```{r}
# Normality test
par(mfrow=c(1,2))
hist(residuals(mlr_interaction_updated_model), breaks = 24)
plot(mlr_interaction_updated_model, which=2) #a Normal plot
```

**Normality test**
H0: the sample data are significantly normally distributed Ha: the sample data are not significantly normally distributed
```{r}
shapiro.test(residuals(mlr_interaction_updated_model))
```
The p-value(2.2e-16) is much lower than 0.05, which confirms that the residuals are not normally distributed (reject null hypothesis).

```{r}
# Build polynomial regression model
mlr_poly_model <- lm(Price ~ poly(Rating, 3) + TotalReviwes + RamSize_inGB + RomSize_inGB + Rating:RamSize_inGB + Rating:RomSize_inGB + TotalReviwes:RomSize_inGB + RamSize_inGB:RomSize_inGB, data = train_data)
summary(mlr_poly_model)
```

```{r}
# Check assumptions of the model
# Plot the residuals vs fitted values
plot(mlr_poly_model, which = 3)
```

```{r}
library(lmtest)
bptest(mlr_poly_model)
```

```{r}
# Normality test
par(mfrow=c(1,2))
hist(residuals(mlr_poly_model), breaks = 24)
plot(mlr_poly_model, which=2) #a Normal plot
```

```{r}
# Check outliers
plot(mlr_poly_model,which=c(5))
```

```{r}
library("MASS")
bc = boxcox(mlr_poly_model,lambda=seq(-1,1))
```

```{r}
bestlambda = bc$x[which(bc$y==max(bc$y))]
mlr_bcmodel = lm((((Price^bestlambda)-1)/bestlambda) ~ poly(Rating, 3) + TotalReviwes + RamSize_inGB + RomSize_inGB + Rating:RamSize_inGB + Rating:RomSize_inGB + TotalReviwes:RomSize_inGB + RamSize_inGB:RomSize_inGB, data=train_data_without_outliers)
summary(mlr_bcmodel)
```

```{r}
# Predict the price of the test data
test_data$predicted_price_mlr_bcmodel <- predict(mlr_bcmodel, test_data)
# Transform the predicted price back to the original scale
test_data$predicted_price_mlr_bcmodel <- (((test_data$predicted_price_mlr_bcmodel*bestlambda)+1)^(1/bestlambda))
# Calculate the mean square error
mse <- mean((test_data$Price - test_data$predicted_price_mlr_bcmodel)^2)
# Print the mean square error
print(paste("Mean square error:", mse))
```

```{r}
# Normality test
par(mfrow=c(1,2))
hist(residuals(mlr_bcmodel), breaks = 24)
plot(mlr_bcmodel, which=2) #a Normal plot
```

```{r}
library(lmtest)
bptest(mlr_bcmodel)
```

```{r}
shapiro.test(residuals(mlr_bcmodel))
```

```{r}
# predict the price of the test data
test_data$predicted_price_mlr_bcmodel <- predict(mlr_bcmodel, test_data)
# Calculate the mean square error
mse <- mean((test_data$Price - test_data$predicted_price_mlr_bcmodel)^2)
# Print the mean square error
print(paste("Mean square error:", mse))
```

```{r}
```
```{r}
# remove outliers
n = nrow(train_data)
p = length(coef(mlr_bcmodel))
lev=hatvalues(mlr_bcmodel)
outlier3p = lev[lev>(3*p/n)]
print(outlier3p)
```

```{r}
plot(rownames(train_data), lev, main = "Leverage in Mobile Dataset", xlab = "observation", ylab = "Leverage value")
abline(h = 3*p/n)
```
```{r}
# remove outliers
# Find the row indices of the outliers in the train_data data frame
outlier_indices = which(lev %in% outlier3p)

# Remove the outliers from the train_data data frame
train_data_without_outliers = train_data[-outlier_indices, ]
```

```{r}
# K-mean clustering of Price
library(cluster)
library(tidyverse)
# Select only the Price column
price_data <- mobile_dataset[, "Price"]
# Scale the data
scaled_data <- scale(price_data)
set.seed(123)
kmeans_model <- kmeans(scaled_data, centers = 4)
# Add the cluster column to the mobile_dataset data frame
mobile_dataset$cluster <- kmeans_model$cluster
# Plot the clusters
ggplot(mobile_dataset, aes(x = Price, y = cluster, color=factor(cluster))) +
        geom_point() +
        # vertical line at the mean price
        geom_vline(xintercept = 9500, color = "red", linetype = "dashed") +
        geom_vline(xintercept = 24400, color = "red", linetype = "dashed") +
        geom_vline(xintercept = 55000, color = "red", linetype = "dashed") +
        scale_fill_manual(values = c("blue", "red", "green", "purple"),
                          labels = c("Cheap", "Affordable", "Expensive", "Luxury"),
                          name = "Price Category")

# Chekc the Price threshold values
price_thresholds <- mobile_dataset %>% group_by(cluster) %>% summarize(min_price = min(Price), max_price = max(Price))
print(price_thresholds)
```

```{r}
# Fit a regression tree to the data
library(tree)
tree_model <- tree(Price ~ ., data = train_data)
summary(tree_model)
```
```{r}
# Plot the tree
plot(tree_model)
text(tree_model, pretty = 0)
```
```{r}
# Apply the tree to the test set
tree_pred <- predict(tree_model, test_data)
# Calculate the RMSE
mse <- mean((tree_pred - test_data$Price)^2)
mse
```

```{r}
# Check the plot between the cross-valiation error and the size of the tree
cv.tree_model <- cv.tree(tree_model)
plot(cv.tree_model$size, cv.tree_model$dev, type = "b")
```
```{r}
# Prune the tree
pruned_tree_model <- prune.tree(tree_model, best = 6)
# Plot the pruned tree
plot(pruned_tree_model)
text(pruned_tree_model, pretty = 0)
```
```{r}
# Apply the tree to the test set
pruned_tree_pred <- predict(pruned_tree_model, test_data)
# Calculate the RMSE
mse_pruned <- mean((pruned_tree_pred - test_data$Price)^2)
```

While improving the model's explanatory power (Adjusted R-squared), the model's performance on the test data has decreased. This is because the model is overfitting the training data. The model is not generalizing well to the test data. The model is not able to predict the price of the test data accurately.

```{r}
References

2020 review. “High-End Mobile Phones Price Have Soared 490% in 20 Years | This Is Money.” This Is Money, This Is Money, 23 July 2020, https://www.thisismoney.co.uk/money/bills/article-8548235/High-end-mobile-phones-price-soared-490-20-years.html.  

MobilePhone's dataset. “MobilePhone’s Dataset | Kaggle.” Kaggle: Your Machine Learning and Data Science Community, Kaggle, 20 Dec. 2022, https://www.kaggle.com/datasets/sudhanshuy17/mobilephone.

centrality, betweenness, closeness, and